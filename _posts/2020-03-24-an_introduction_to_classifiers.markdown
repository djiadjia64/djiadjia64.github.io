---
layout: post
title:      "An Introduction to Classifiers"
date:       2020-03-24 07:27:35 +0000
permalink:  an_introduction_to_classifiers
---


For this project, I used a multitude of classifier methods and fitted a dataset regarding the probabilities of a customer cancelling a phone service. The dataset I used has variables such as phone call time during the day or night and other descriptors such as area code or state. I dropped some columns I deemed irrelevant, such as phone number and state and put the dataset through a train test split with SMOTE to help deal with the imbalanced dataset. For this scenario, I ended up choosing overbalancing the data.  After performing the neccesary EDA, my first idea was to fit the data with XGBoost, an extremely popular and successful classifier which has already won many competitions on Kaggle. The initial attempts were pretty smooth. The training and testing set were very close with a very high accuracy at 94%. This was pretty surprising to me as most as my previous uses of classifiers gave me a much lower accuracy. I ran the data through and created a confusion matrix, once again reaffirming my results. I had a true Positive of 85% and false negative of 12%. To better optimize my data, I employed the module CVGridSearch to help optimize my hyperparameters. To be honest, this module was very frustrating. Whether it be my computer power or the large datasets employed, the time it took to run the GridSearch seemed to take forever. Combined with several syntax errors and other miscellaneous mistakes, the time it took to run my first successful CVGridSearch was exponential. Once I was able to get it working however, my benefits it provided was worth the headache. After running my XGBoost function once again, I got a accuracy of 97%, though my confusion matrix results were still about the same. 

Though I was pretty satisfied with the results I was able to get with XGBoost, I tried a couple of other classifier methods just in case those turned out to be better. Adaboost is an algorithm that works with many small decision trees, called "stumps" due to their singular nature. This algorithm combines the results of these stumps in a way that is able to optimize machine learning by weighting trees more than others through a sort of trial-and-error approach. It's very similar to XGBoost as they both employ methods of Gradient Boosting. Gradient Boosting is a process in which hard-to-classify situations are weighted more greatly while easy classifications are weighted lower. The higher-weighted trees are then used for secondary nodes and etc. Ultimately, we are using weak-learners to gradually create strong-learners. 

After I had my confusion matrix and an algorithm fit for my data, the next step was to apply this knowledge practically to the broader question at hand.  Looking at feature importance was very helpful, simply allowing one to see how important each feature was weighed in the algorithm. Using this knowledge allowed me to determine which variable to focus on the most. 

My Adaboost results were a little bit worse than my XGBoost results but still pretty good at around 84% accuracy. I went through the same process with Gradient Boost and Random Forest. Both these results were comparable with Adaboost at 87% and 93% accuracy respectively but still a little bit worse than my XGBoost accuracy. 

Conclusions:
Machine learning algorithms seem daunting and unfamiliar at first. A lot of the calculations are happening behind-the-scenes, and it is easy to feel lost as the machine returns you a large variety of data and numbers. However, I've found that working with these classifiers in a practical manner with a set goal, it makes conceptualizing these algorithms a lot more palatable. Also, this project exposed me to the complexitiy and endless-usefulness offered by these crafted algorithms. They allow to perform different calculations on endless data effortlessly as well as return many useful statistics. Still, I think it is important to recognize that it is the data scientist or mathematician that makes the important decisions beforehand, and the validity or usefulness of the returned statistics are only as significant as the data or parameters initially used. One must be able to use the analysis in a practical manner as well. That was also what I found to be relatively challenging personally. Although I had set-up algorithms to analyze the data, finding applicable conclusions ended up to be alot harder than expected. You had to be able to relate the data to the goal ultimately.

I was able to finally use my model in a practical manner after staring at several charts for what seemed like forever. Though the visuals were clear and the models useful, it took a human eye to discern distinct patterns in the data. I deduced that a charge of between 40 and 60 dollars was a sweet spot in terms of keeping customers. Also, customer service calls dramatically impacted whether the customer cancelled or not. With these observations, I proposed some ideas that may or may not improve the performance of the service and will take further tests to conclude results. Overall, this was a great opportunity for me dive deeper into the concepts and capabilities offered by a multitude of classifier algorithims. 
